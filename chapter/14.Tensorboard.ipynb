{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f9a6fe",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118cf06c",
   "metadata": {},
   "source": [
    "TensorFlow에서 제공하는 시각화 툴입니다. 학습하는 중간의 그래프나 여러가지 정보를 Web UI로 조회할 수 있습니다! \n",
    "\n",
    "https://www.tensorflow.org/tensorboard?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32fb3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c40f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7777)\n",
    "tf.random.set_seed(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfbead7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) float32\n",
      "(50000, 10) float32\n",
      "(10000, 32, 32, 3) float32\n",
      "(10000, 10) float32\n"
     ]
    }
   ],
   "source": [
    "class Cifar10DataLoader():\n",
    "    def __init__(self):\n",
    "        # data load\n",
    "        (self.train_x, self.train_y), \\\n",
    "            (self.test_x, self.test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "        self.input_shape = self.train_x.shape[1:]\n",
    "\n",
    "    def scale(self, x):\n",
    "\n",
    "        return (x / 255.0).astype(np.float32)\n",
    "\n",
    "    def preprocess_dataset(self, dataset):\n",
    "\n",
    "        (feature, target) = dataset\n",
    "\n",
    "        # scaling #\n",
    "        scaled_x = np.array([self.scale(x) for x in feature])\n",
    "\n",
    "        # label encoding #\n",
    "        ohe_y = np.array([tf.keras.utils.to_categorical(\n",
    "            y, num_classes=10) for y in target])\n",
    "        \n",
    "        return scaled_x, ohe_y.squeeze(1)\n",
    "\n",
    "    def get_train_dataset(self):\n",
    "        return self.preprocess_dataset((self.train_x, self.train_y))\n",
    "\n",
    "    def get_test_dataset(self):\n",
    "        return self.preprocess_dataset((self.test_x, self.test_y))\n",
    "\n",
    "cifar10_loader = Cifar10DataLoader()\n",
    "train_x, train_y = cifar10_loader.get_train_dataset()\n",
    "\n",
    "print(train_x.shape, train_x.dtype)\n",
    "print(train_y.shape, train_y.dtype)\n",
    "\n",
    "test_x, test_y = cifar10_loader.get_test_dataset()\n",
    "\n",
    "print(test_x.shape, test_x.dtype)\n",
    "print(test_y.shape, test_y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c511a44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 16)   448         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 16)    0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 32)     544         ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 8, 8, 32)     9248        ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 8, 8, 32)     544         ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 32)     1056        ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 8, 8, 32)     0           ['conv2d_12[0][0]',              \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 32)     1056        ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 32)     9248        ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 8, 8, 32)     1056        ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 8, 8, 32)     0           ['add_2[0][0]',                  \n",
      "                                                                  'conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 32)    0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 512)          0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           5130        ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,330\n",
      "Trainable params: 28,330\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Add\n",
    "\n",
    "def build_resnet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    net = Conv2D(16, kernel_size=3, strides=2,\n",
    "                 padding='same', activation='relu')(inputs)\n",
    "    net = MaxPool2D()(net)\n",
    "    \n",
    "    net1 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net)\n",
    "    net2 = Conv2D(32, kernel_size=3, padding='same', activation='relu')(net1)\n",
    "    net3 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net2)\n",
    "    \n",
    "    net1_1 = Conv2D(32, kernel_size=1, padding='same')(net)\n",
    "    net = Add()([net1_1, net3])\n",
    "    \n",
    "    net1 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net)\n",
    "    net2 = Conv2D(32, kernel_size=3, padding='same', activation='relu')(net1)\n",
    "    net3 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net2)\n",
    "    \n",
    "    net = Add()([net, net3])\n",
    "    \n",
    "    net = MaxPool2D()(net)\n",
    "    \n",
    "    net = Flatten()(net)\n",
    "    net = Dense(10, activation=\"softmax\")(net)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=net, name='resnet')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_resnet((32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e229ea",
   "metadata": {},
   "source": [
    "### fit 함수로 학습 할 때는 callback 함수로 사용! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e30ef461",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6d33882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 2.3393 - accuracy: 0.1000 - val_loss: 2.3277 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.3402 - accuracy: 0.1017 - val_loss: 2.3555 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.3421 - accuracy: 0.0991 - val_loss: 2.3084 - val_accuracy: 0.1000\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.3434 - accuracy: 0.0991 - val_loss: 2.3140 - val_accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.3445 - accuracy: 0.1014 - val_loss: 2.4095 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19fc6ebe0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_x, \n",
    "          y=train_y, \n",
    "          epochs=5,\n",
    "          validation_data=(test_x, test_y),\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55a907db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "TensorBoard 2.7.0 at http://Brians-MacBook-Pro.local:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/fit --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905ad94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9762d2dc",
   "metadata": {},
   "source": [
    "### tf.summary 사용하기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4426f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.categorical_crossentropy\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y) :\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(y, pred)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, pred)\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y) :\n",
    "    \n",
    "    pred = model(x)\n",
    "    loss = loss_fn(y, pred)\n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_accuracy(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff76638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db80da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0682d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da9fecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "440d048c",
   "metadata": {},
   "source": [
    "### Tensorboard에 이미지 데이터 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdcc0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_x[777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd24b9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40688965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbQElEQVR4nO2dbYxcZ3XH/2fedry73l07doxjGxKSAIpoE9AqSgVCFESVIqSAVEXwAeVDhFFFpCJRqVEqlVTqB6gKER8qKtNEhIoSUl5EVEUtIUKNUKsQJwTnDUhiHBKz8TrJel9n5+Xe0w8zljbR/Z/dnZ2ddXj+P8ny7D3z3HvmuffMnXn+c84xd4cQ4g+f0k47IIQYDgp2IRJBwS5EIijYhUgEBbsQiaBgFyIRKlsZbGbXA/gagDKAf3X3L0XPH5/c4xddfEmhbdACYLS//o/Vz0jje3szyJ7c/eFygczV9nix+b2y6Zg/+zJWFs4VnrW+g93MygD+GcBHALwE4BEzu8/dn2ZjLrr4Etx6xz2Ftiw4mTm54DyYpMz4VdqhljgA+wtO7keeXRgXcG7B3JfyPvda/Lqj947ofCJrBwODcfSA/b2LRT72O1PsunLne8zzYttdf3OUjtnKx/hrATzn7ifdvQXgHgA3bGF/QohtZCvBfgjAi2v+fqm3TQhxAbLtC3RmdtTMjpvZ8aX5ue0+nBCCsJVgPw3gyJq/D/e2vQ53P+bu0+4+PT65ZwuHE0Jsha0E+yMArjSzy8ysBuCTAO4bjFtCiEHT92q8u3fM7BYA/42u9HaXuz8VDjJDuUIOGaw8soV1DxZUy4GtFtjYKmfXD7LCHKz8RwSHCtWYcEU43/wKf2bckWzTezsP8SN0Lzqh1T7dICvd/e0tVo2CvUZXCLt+IvWHXael4Frcks7u7vcDuH8r+xBCDAf9gk6IRFCwC5EICnYhEkHBLkQiKNiFSIQtrcZvlpIBI0RByQMdLetDerMgucMCQSmSO/qS3iIJzft7r/XghfOkCu5IJ3AyssWvrVgaCuWk8FCheBWYmK0/8a0U5epEA8MkKiYPRtcisQVToTu7EImgYBciERTsQiSCgl2IRFCwC5EIQ12NLxswMVK8XNgJViszsirJylUB8Wp89A4Xr/qSYwWrpuEabJQJEw2MFv9Z/kk0v4GakKFMbXm4wlw8y9Fr7gRlurLgrEXnrL8cpWg+gqShqKRZIDX0V5aqeEz0cnVnFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCIMXXqbHCmWE9rO0wg6LKkiqiUXOXJhNGKJa9D1ST+JMLH0FnS0iRqxsLpqwWtuB1kmLecSYCh5EZtFbbmiCySYq0DthUdGJlMGFzirQRdJjbqzC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhG2JL2Z2SkAi+iW3+q4+3Q8IkOps1xoGa1yV1h2G8uG647h72P5OnlvgyWQeIK0vX69YHJNlG0WSm/RPAb7ZPJVHkpQUfYg96MUaIDMx7jNFzWFRFlqUQ26Uomcs+BYzMfI9UHo7H/q7q8MYD9CiG1EH+OFSIStBrsD+LGZPWpmRwfhkBBie9jqx/j3u/tpM7sYwANm9it3f2jtE3pvAkcB4MCBt2zxcEKIftnSnd3dT/f+nwXwQwDXFjznmLtPu/v05J6prRxOCLEF+g52Mxszs93nHwP4MwBPDsoxIcRg2crH+AMAftjLbqoA+Hd3/69oQLvdxszLLxXa9ly0j46r7dpVbCjxTKhSkDFkYboWN7HeP3FGU7S/YPqjlL4INiyS0CwobOgtbuPTj4xJgMHtpVrhOyRXAACg3QlkxaxT7EfYuipqh8XPSzvItQzbijGRLbiuMmLbFunN3U8CuLrf8UKI4SLpTYhEULALkQgKdiESQcEuRCIo2IVIhKEWnGy12njh92cKbWcXGnRcrT5auH109wQds2diitpGayPUluXFUg0QZI4FhRKNZDQBcY84VrARiGUcZqoEslbW4vJaa3WF2qp1LoiNVIvnuBnIZKsr/FiLC+eobX6e21qtduH2w4cP0zFTU1PU1gz60eVR5mbY641l5gXSGzEFl5vu7EKkgoJdiERQsAuRCAp2IRJBwS5EIgx1Nb7RbOHpZ18stJWrdTrOKtXC7e2Mr+xeefnl1PZHV72T2ipV/v5XLhX7YWHfH+5jKUygCeqZBeNY7bd2UHNteWWVHyvjy7sj9Rq1NVaKVY3HHj9Bx5z63SnuRsbVmiwrXnHv2orbip08+Rwdc/XV11DbgUN8FZ/VkgMACxQbpqCUg/2VSP1CtX8SQijYhUgFBbsQiaBgFyIRFOxCJIKCXYhEGKr0luWO+eVimSRHsUQCAB0iTQQ5FVhp/pralptcxnnr4UPUNjVZnHgT5JigXi+W6wCgWo0qhkX1zIJhRHqrVrhMVqnwy6DZ5LJWq8V9fOLJZwq3/89DP6NjItnoon086SaSPlnS0Guv8SZGDz/8v9R26eVXUNuV73wXte0KkobYy2YyKgBYfBEUoju7EImgYBciERTsQiSCgl2IRFCwC5EICnYhEmFd6c3M7gLwMQCz7v7u3ra9AL4L4FIApwDc6O5z6+3LHejkxRJb5oH0RhQeD9onLa9yee3Zk89T25kzM9Q2NT5euL1e5drb4UO8c+3bLz9CbeVKoEMFpoxkAtZrfK4qY8U1/gBg7iyfj5lZLl/9/vTpwu179+ylYyYmd1NbdYTXyZubO0ttVKAK5Lr5oN7diRO/oLbG6jK1HTnMz/XE5GTh9vHxMTqGJcRFdQ03cmf/JoDr37DtVgAPuvuVAB7s/S2EuIBZN9h7/dZfe8PmGwDc3Xt8N4CPD9YtIcSg6fc7+wF3P//57mV0O7oKIS5gtrxA593fI/KvRmZHzey4mR2PapALIbaXfoP9jJkdBIDe/7Psie5+zN2n3X2aNXsQQmw//Qb7fQBu6j2+CcCPBuOOEGK72Ij09h0AHwSwz8xeAvBFAF8CcK+Z3QzgBQA3buxwOYAmOxAdVS4TaSt4qyqVuDEnRQgBYH6Of9VoLrxxnbLLaJVntl00xltNdVa4DNWJEuICW06kt3MN/rosuAyyPGgN1eb7vPIdlxVuv/SK4u0AUCrzF3Zu/vfUNjdHP1giy4oLX3Y6/BqI8ODaef5Znml5NpB09+3fX7h9P9kOAObFc9Vs8uKh6wa7u3+KmD683lghxIWDfkEnRCIo2IVIBAW7EImgYBciERTsQiTCUAtOGnKUQOQa4+87bsTNYEzUoywHz1IrBz3RKiTL7rKg/9cVb+UFLL3FZa3lFS5r5YGPrXbxPhsNngXYCnrmtYKqnlbml0+N9OebX1jix2oRWRZArcbP2YEDF1PbzAyTvILXRS2ABRJxnvHzOX/uVWpbXCxOGH3pd7/ljuTFP1pdWeaZd7qzC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhGGKr3l3kGzUSxBeCR4MIktyGwrM7kOQB7YPOgfV5qYKty+Z6q4YCAALC9xKaTZ4n3UVoLspRYp2gkAq53iLK/lVb6/rF08BgAaDS6HZUHBTy8Xy0mLS4t0TLvFfazXea+6ZtC7r90mJ5TMEwBY0HfQSrygYx5cPJ0gW471o2sGMh+zZDl/XbqzC5EICnYhEkHBLkQiKNiFSAQFuxCJMNTVeM+BdrN4VZKtSAJArVq8Eps7X3nMLWgnBb4KXgpUgeXF4pXkqckJOmbv5B5qm32VJ0eUM17Xrmp8ZbqRF69oe4XPbzVQJ6rlOrW9usITP2Zmi1fjO51gdb/Nba/McVUjSkDJyUq9NxfomGqJXzskv6d7rEBQ6gSr/9VK8fyXyXaAJw15oNTozi5EIijYhUgEBbsQiaBgFyIRFOxCJIKCXYhE2Ej7p7sAfAzArLu/u7ftdgCfAXC297Tb3P3+9fZVHxnDO6+4rtAWSW+s7ldUi60USCTlaiRDcf1k90ix5HXkEt6xem8gy01M8tZQK0HiSu78PbpBkmssSFopB3LN6Nhuanv+5WJ5DQB+8n+PFG5vBvJalKCEcpChFCR/tLPic+1B9ycL5Nesw6+dUiVIzKruorZKrfhizYLagEuNYikyCIkN3dm/CeD6gu13uPs1vX/rBroQYmdZN9jd/SEAxR0NhRBvGrbynf0WMzthZneZGf+ZmBDigqDfYP86gMsBXANgBsBX2BPN7KiZHTez46vke4YQYvvpK9jd/Yy7Z+6eA/gGgGuD5x5z92l3n67vGuvXTyHEFukr2M3s4Jo/PwHgycG4I4TYLjYivX0HwAcB7DOzlwB8EcAHzewaAA7gFIDPbuRg5XIF4xMXsePQcUyWC9Q61Ea5rFUb57rcSKDJvPXiqcLtRw69hY5pN3jNtVGeUIa8w/1oNbl8NUam0Ts8088C6W2yzuvrjdUDOY/cRsqVSG7kmWirK7zOHHL+2i7eXyyL7h7lLbuqQZ256ghvQ1Ub4a8tur7ZhRxlyq00iqXZ3/z8KTpm3WB3908VbL5zvXFCiAsL/YJOiERQsAuRCAp2IRJBwS5EIijYhUiEIbd/ytBoF8srgTBBieSMvB1k0XW4RDJS4+9/By85VLh9/4GL6ZjVJS7zTTjPiDPW8gqAZ8FskaqHnTaX18rB7laCLK+5X71IbW0yrtXhaVmvvjZPbRa0Vpqa5Jl5bTJX55Z4VuFYINuO1bltfHSK2up1rrPWaryAKKNDMuJqI/w4urMLkQgKdiESQcEuRCIo2IVIBAW7EImgYBciEYYqvcHiQpCb3l0gGVWq3FgOZK1alTtYIj3nTp99hY5ZXT5HbQiy9paWVrgxKMyYe/HrXlhYomOi/nYLDd5H7bkXZ6itA5IdVuJzX9/FZaOpCS5T7tu3l9pWGsWvO+/w1+VVLq/lJV44smN8XBbY2ii+5kqRtFwiUmRwbevOLkQiKNiFSAQFuxCJoGAXIhEU7EIkwnBX42EA+KokHUVWJUvBym7Z+Kp61O6o2eB1vx4/8UTh9kfbvET2/Nyr1GYdvtraIW2LAKAR1KdjtoUVvrq/vMhtq02egLJa4ueyPlHcSqBa42P2799PbbuCBJRWkOQD0vaqNsqTT6zC68xlgZy0GiRfdZzXySu3iseVWSE/AEzKyfOgPVWwNyHEHxAKdiESQcEuRCIo2IVIBAW7EImgYBciETbS/ukIgG8BOIDuev8xd/+ame0F8F0Al6LbAupGd59bZ2/Ici5rcB+K35M8SOBocwUNpRKXajo5l5qYsjI7yxNhfnvyOb6/ZS55BSXXsNzmMk6HzEk7kGSiuXKSpAEAtVGenDJRKpa2Jid4vbjxEZ5kEiWuNFq8nhwqxdeORRlZwXysZtwPVncPAMolfq2WiMQWJXoxUyfj1/ZG7uwdAF9w96sAXAfgc2Z2FYBbATzo7lcCeLD3txDiAmXdYHf3GXd/rPd4EcAzAA4BuAHA3b2n3Q3g49vkoxBiAGzqO7uZXQrgPQAeBnDA3c8nNL+M7sd8IcQFyoaD3czGAXwfwOfd/XXF373bU7nwC4uZHTWz42Z2vLHMCygIIbaXDQW7mVXRDfRvu/sPepvPmNnBnv0ggNmise5+zN2n3X1619j4IHwWQvTBusFu3SyUOwE84+5fXWO6D8BNvcc3AfjR4N0TQgyKjWS9vQ/ApwE8YWaP97bdBuBLAO41s5sBvADgxvV25AAyEE0pqMfGjBbIU55xia/d4ppGUMILZaZq1LkEtfeSt1HbwqtnqG1+jquY7SATLSPZcu0gM6wVzGN0OygHklebfGXLSR0/AFhZ4Y6sLPPswV2TY9RWGy3+NFmvcz9GKoEsRyTFri0Kp+Cc5cVSqgUXOM9u44G0brC7+8/AZb0PrzdeCHFhoF/QCZEICnYhEkHBLkQiKNiFSAQFuxCJMNyCk+7ImGTggfZG0n+CpCB4lLoUZIBZkJ1kRL7KA7ljZNcotxFZCACycwvU1gyyqzrtYrlmcZEXxSwHUlOtziXMvN2kttZqcUbf3Kvc91fOFv4uCwDQbvNfX77tHZdRW3W8eP4tKFaaB5mPpTB7jc+VBfdVK5GCkxV+rGqlOHRLJe6D7uxCJIKCXYhEULALkQgKdiESQcEuRCIo2IVIhKFKbzmAVodlvUVpb0R6i2SQoJ+bIyjKF739WfE4d76/dodLgJUaL7BY28ULM1ZWuTTkVny8Wp0OQdRSLJrHZoMXzGysNAq3Z/nm5SQAKJW5bZkcCwAmyP0skhsR9NmLLtM8C86L8+sgJzYLZLQymcaoSKXu7EIkgoJdiERQsAuRCAp2IRJBwS5EIgx1Nd7d0WKr01EeDFl1Lzl/rwoW6mHBkmUe9F3KSa2wPFiNj1bqK8GK8NguXletExSNa1hxXbiobl1j8Ry1LS/Ocz+Cpelavdj/qb376JgDbzlIbSvLi9S2tMITctpkhbwdrLhXPFB5wtX4IPnK+MBqtTgMKxW+Gp+RY3lwTnRnFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCKsK72Z2REA30K3JbMDOObuXzOz2wF8BsDZ3lNvc/f7o325A03ahiioC0ekskhmCJQOlKNsgainFGnhEyU5BGXJYEGSTDVoFzQf1Go7e/a1wu2NBm/VhE6LmkqBH9Uab4XEkmtqI/ySawd+LDd4sgtGuITJ8q5WW0GCUiC9WTAfUeuwWuAjqxsXScT93Kc3orN3AHzB3R8zs90AHjWzB3q2O9z9nzZ9VCHE0NlIr7cZADO9x4tm9gyAQ9vtmBBisGzqs4CZXQrgPQAe7m26xcxOmNldZrZn0M4JIQbHhoPdzMYBfB/A5919AcDXAVwO4Bp07/xfIeOOmtlxMzveXOG1y4UQ28uGgt3MqugG+rfd/QcA4O5n3D1z9xzANwBcWzTW3Y+5+7S7T4+M8t97CyG2l3WD3bpLgncCeMbdv7pm+9qshU8AeHLw7gkhBsVGVuPfB+DTAJ4ws8d7224D8CkzuwZdzewUgM+utyN3R4e11glr0BWTh9JbkGUUKBoeSoBMNuRyTKddnCkHANWgfVJj4Ry1zc3O8OM1iuWrcqAoWpDpF6YjBm2SmLzZyfh8LC4FLa+CeRwlLZ4A0KJs9DoEgCjrjY9COdDeIhGt0ym+rjKSZdnd3+bl6I2sxv8Mxb6GmroQ4sJCv6ATIhEU7EIkgoJdiERQsAuRCAp2IRJhuAUn4cg7xXJCJBkwU5i8FsggWSCEhFlNxGbgGVSrjSVqWw7ktaVz3FYKjlcuERknkK48kKGieSwFl0+JVPxsNbnc2GlyH8uVEWqrVrmtuUr2GRQrzYILqxKkMeZRAVT+0lDOyQUeFCtlraFUcFIIoWAXIhUU7EIkgoJdiERQsAuRCAp2IRJhqNIb3IE+elRRaSjq2VbmBf7yUiAZBVleFVKM0nJeKNFbvGBHc5UXUVwKCn20g8yxnMhyTiQ5ALCoOmeARY3PyKmJkhsjm1X4ObPgnpUR6a0dJL3lRNYCgLwWZPoF0ltUAbWE4nMT9QkcGSku9inpTQihYBciFRTsQiSCgl2IRFCwC5EICnYhEmG40huAnMhozjJ/EBeB3OxxegfjtkBOyohsmDW5hNYIJLRGIL2tBtlhWc4lGTpXgfTjwXxEWW9RLzJqi+S1cH/cj35kWydFHgEgD6IiGIaMSGjdA3Ib66fnOc9urFWJtBzMr+7sQiSCgl2IRFCwC5EICnYhEkHBLkQirLsab2Z1AA8BGOk9/3vu/kUzuwzAPQAuAvAogE+7O88IQTfRoUO7P0WrxcW2qAZdtMLsQQ03BAkjq1nxCnlrma+4rzaCFffVVWprtfhURkoDn6uoYB9/z6+wVV8A1Rq3seNFLbuiE1oq9XdfYvMR+hEpQ1mw4h6MQ8ZfW5kkWJUHfCveyO6aAD7k7lej2575ejO7DsCXAdzh7lcAmANw82BdE0IMknWD3bucL5Fa7f1zAB8C8L3e9rsBfHw7HBRCDIaN9mcv9zq4zgJ4AMDzAM65+/nPwy8BOLQtHgohBsKGgt3dM3e/BsBhANcCeNdGD2BmR83suJkdb6+u9OelEGLLbGoJwN3PAfgpgD8BMGVm5xf4DgM4TcYcc/dpd5+u1oM+2kKIbWXdYDez/WY21Xu8C8BHADyDbtD/Re9pNwH40Tb5KIQYABtJhDkI4G4zK6P75nCvu/+nmT0N4B4z+wcAvwBw53o7cnc0WRuiQAphMkkpkGo8aOOUBdJVG0GbpFZxK6dW0OKpGchrq43BS2+MSHqrVvllUK/Xqc3LfBxNyIlaTfHSb4gyPKL5aJPrLesE8muUkFMJEoMC/4NhNBFmpMp32Fgp/koczcW6we7uJwC8p2D7SXS/vwsh3gToF3RCJIKCXYhEULALkQgKdiESQcEuRCJYlG028IOZnQXwQu/PfQBeGdrBOfLj9ciP1/Nm8+Nt7r6/yDDUYH/dgc2Ou/v0jhxcfsiPBP3Qx3ghEkHBLkQi7GSwH9vBY69Ffrwe+fF6/mD82LHv7EKI4aKP8UIkwo4Eu5ldb2a/NrPnzOzWnfCh58cpM3vCzB43s+NDPO5dZjZrZk+u2bbXzB4ws2d7/+/ZIT9uN7PTvTl53Mw+OgQ/jpjZT83saTN7ysz+qrd9qHMS+DHUOTGzupn93Mx+2fPj73vbLzOzh3tx810zq21qx+4+1H8AyuiWtXo7gBqAXwK4ath+9Hw5BWDfDhz3AwDeC+DJNdv+EcCtvce3AvjyDvlxO4C/HvJ8HATw3t7j3QB+A+CqYc9J4MdQ5wSAARjvPa4CeBjAdQDuBfDJ3vZ/AfCXm9nvTtzZrwXwnLuf9G7p6XsA3LADfuwY7v4QgNfesPkGdAt3AkMq4En8GDruPuPuj/UeL6JbHOUQhjwngR9DxbsMvMjrTgT7IQAvrvl7J4tVOoAfm9mjZnZ0h3w4zwF3n+k9fhnAgR305RYzO9H7mL/tXyfWYmaXols/4WHs4Jy8wQ9gyHOyHUVeU1+ge7+7vxfAnwP4nJl9YKcdArrv7Aib724rXwdwObo9AmYAfGVYBzazcQDfB/B5d19YaxvmnBT4MfQ58S0UeWXsRLCfBnBkzd+0WOV24+6ne//PAvghdrbyzhkzOwgAvf9nd8IJdz/Tu9ByAN/AkObEzKroBti33f0Hvc1Dn5MiP3ZqTnrHPodNFnll7ESwPwLgyt7KYg3AJwHcN2wnzGzMzHaffwzgzwA8GY/aVu5Dt3AnsIMFPM8HV49PYAhzYt0CeXcCeMbdv7rGNNQ5YX4Me062rcjrsFYY37Da+FF0VzqfB/C3O+TD29FVAn4J4Klh+gHgO+h+HGyj+93rZnR75j0I4FkAPwGwd4f8+DcATwA4gW6wHRyCH+9H9yP6CQCP9/59dNhzEvgx1DkB8MfoFnE9ge4by9+tuWZ/DuA5AP8BYGQz+9Uv6IRIhNQX6IRIBgW7EImgYBciERTsQiSCgl2IRFCwC5EICnYhEkHBLkQi/D/HMkG9Blbh7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad789e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249cc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb90cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baad7b49",
   "metadata": {},
   "source": [
    "### LambdaCallback을 사용하여 Tensorboard에 Confusion Matrix 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9ce0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    threshold = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure\n",
    "\n",
    "logdir = \"logs/fit/cm/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "test_images = test_x[:100]\n",
    "test_labels = np.argmax(test_y[:100], axis=1)\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    test_pred_raw = model.predict(test_images)\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "    \n",
    "    classes = np.arange(10)\n",
    "    cm = confusion_matrix(test_labels, test_pred, labels=classes)\n",
    "    \n",
    "    figure = plot_confusion_matrix(cm, class_names=classes)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7c8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72feba37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6917a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63380895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f961f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de3a18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b208b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6900f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d97677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2b58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
