{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b24a329",
   "metadata": {},
   "source": [
    "# ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dd977728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0206df9d",
   "metadata": {},
   "source": [
    "### ImageDataGenerator \n",
    "\n",
    " - 데이터를 불러오는 동시에 여러가지 전처리를 쉽게 구현 할 수 있는 tf.keras의 기능! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1fb53047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "181ff975",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,        # 회전하는 각도를 랜덤하게\n",
    "    width_shift_range=0.2,      # 가로로 이동하는데 20% 만큼\n",
    "    height_shift_range=0.2,     # 아래 위로\n",
    "    horizontal_flip=True        # 좌우 반전\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a50e3d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen.flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2736a18",
   "metadata": {},
   "source": [
    "## Data Augmentation (데이터 증강기법) -> Overfitting 방지\n",
    "- 딥러닝은 내가 본 데이터 한에서 잘 작동하게끔 되어있는 것이기에, general한 환경에서도 잘 작동할 수 있도록 하는것\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929a0e2c",
   "metadata": {},
   "source": [
    "### flow\n",
    "\n",
    "- 데이터를 모두 메모리에 불러두고 사용 할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "184291e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) float32\n",
      "(50000, 10) float32\n"
     ]
    }
   ],
   "source": [
    "class Cifar10DataLoader():\n",
    "    def __init__(self):\n",
    "        # data load\n",
    "        (self.train_x, self.train_y), \\\n",
    "            (self.test_x, self.test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "        self.input_shape = self.train_x.shape[1:]\n",
    "\n",
    "    def scale(self, x):\n",
    "\n",
    "        return (x / 255.0).astype(np.float32)\n",
    "\n",
    "    def preprocess_dataset(self, dataset):\n",
    "\n",
    "        (feature, target) = dataset\n",
    "\n",
    "        # scaling #\n",
    "        scaled_x = np.array([self.scale(x) for x in feature])\n",
    "\n",
    "        # label encoding #\n",
    "        ohe_y = np.array([tf.keras.utils.to_categorical(\n",
    "            y, num_classes=10) for y in target])\n",
    "        \n",
    "        return scaled_x, ohe_y.squeeze(1)\n",
    "\n",
    "    def get_train_dataset(self):\n",
    "        return self.preprocess_dataset((self.train_x, self.train_y))\n",
    "\n",
    "    def get_test_dataset(self):\n",
    "        return self.preprocess_dataset((self.test_x, self.test_y))\n",
    "\n",
    "cifar10_loader = Cifar10DataLoader()\n",
    "train_x, train_y = cifar10_loader.get_train_dataset()\n",
    "\n",
    "print(train_x.shape, train_x.dtype)\n",
    "print(train_y.shape, train_y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b251cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen.flow((train_x, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "23fee82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = next(iter(datagen.flow((train_x, train_y))))\n",
    "\n",
    "x,y = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "01543019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3c520eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b4acdd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "18cdd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "30b2f00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6701d8",
   "metadata": {},
   "source": [
    "### flow_from_directory \n",
    "- 데이터를 모두 메모리에 불러오기 힘들 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fc452f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./datasets/mnist_png/training\"\n",
    "        # 알아서 레이블과 이미지를 받아옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "04474f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(train_dir+'/9')\n",
    "            # 데이터 셋을 특정해서 정의해 놓아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "80a8ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "                       # 1 채널\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a21927d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 10 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x178742370>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gen = \n",
    "datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = input_shape[:2],        # 어떤 크기로 줄여줄지\n",
    "    batch_size = batch_size,\n",
    "    color_mode = 'grayscale'    # 1채널이기 때문 // rgb, rgba\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c4602e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(datagen.flow((train_x, train_y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7edd31d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 32, 3)\n",
      "(32, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ee161",
   "metadata": {},
   "source": [
    "### flow_from_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b5794e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d042b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir('./datasets/cifar/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6c437542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../datasets/cifar/train/32270_deer.png</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../datasets/cifar/train/21851_cat.png</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../datasets/cifar/train/48309_deer.png</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../datasets/cifar/train/33547_truck.png</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../datasets/cifar/train/45202_automobile.png</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>../../datasets/cifar/train/24599_horse.png</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>../../datasets/cifar/train/38514_automobile.png</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>../../datasets/cifar/train/20054_deer.png</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>../../datasets/cifar/train/25602_bird.png</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>../../datasets/cifar/train/46506_deer.png</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  class_name\n",
       "0            ../../datasets/cifar/train/32270_deer.png        deer\n",
       "1             ../../datasets/cifar/train/21851_cat.png         cat\n",
       "2            ../../datasets/cifar/train/48309_deer.png        deer\n",
       "3           ../../datasets/cifar/train/33547_truck.png       truck\n",
       "4      ../../datasets/cifar/train/45202_automobile.png  automobile\n",
       "...                                                ...         ...\n",
       "49995       ../../datasets/cifar/train/24599_horse.png       horse\n",
       "49996  ../../datasets/cifar/train/38514_automobile.png  automobile\n",
       "49997        ../../datasets/cifar/train/20054_deer.png        deer\n",
       "49998        ../../datasets/cifar/train/25602_bird.png        bird\n",
       "49999        ../../datasets/cifar/train/46506_deer.png        deer\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./datasets/cifar/train_dataset.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1ec7c184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 path\n"
     ]
    }
   ],
   "source": [
    "# fix_path = train_data['path']\n",
    "fix_path = pd.DataFrame(train_data['path'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc75acd",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6fc42",
   "metadata": {},
   "source": [
    "## 문제점 발견\n",
    "- path 주소가 다르다\n",
    "- ../../datasets 가 아니고, ./datasets로 바뀌어야 한다..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2694c50f",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e49f4b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/newrandom/miniforge3/envs/TF/lib/python3.8/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 50000 invalid image filename(s) in x_col=\"path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DataFrameIterator at 0x178745e50>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gen = \n",
    "datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    x_col='path',\n",
    "    y_col='class_name',\n",
    "    target_size = (32, 32),\n",
    "    color_mode = 'rgb',\n",
    "    class_model = 'categorical',\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fcd0d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(datagen.flow((train_x, train_y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "65a7f25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 32, 3)\n",
      "(32, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c543c",
   "metadata": {},
   "source": [
    "학습시켜보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e7381a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 16, 16, 32)   896         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 32)    0           ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 8, 64)     2112        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 8, 8, 64)     36928       ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 8, 8, 64)     2112        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 8, 8, 64)     4160        ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 8, 8, 64)     0           ['conv2d_20[0][0]',              \n",
      "                                                                  'conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 8, 8, 64)     4160        ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 8, 8, 64)     36928       ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 8, 8, 64)     4160        ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 8, 8, 64)     0           ['add_4[0][0]',                  \n",
      "                                                                  'conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 64)    0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 1024)         0           ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           10250       ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 101,706\n",
      "Trainable params: 101,706\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Add\n",
    "\n",
    "def build_resnet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    net = Conv2D(32, kernel_size=3, strides=2,\n",
    "                 padding='same', activation='relu')(inputs)\n",
    "    net = MaxPool2D()(net)\n",
    "    \n",
    "    net1 = Conv2D(64, kernel_size=1, padding='same', activation='relu')(net)\n",
    "    net2 = Conv2D(64, kernel_size=3, padding='same', activation='relu')(net1)\n",
    "    net3 = Conv2D(64, kernel_size=1, padding='same', activation='relu')(net2)\n",
    "    \n",
    "    net1_1 = Conv2D(64, kernel_size=1, padding='same')(net)\n",
    "    net = Add()([net1_1, net3])\n",
    "    \n",
    "    net1 = Conv2D(64, kernel_size=1, padding='same', activation='relu')(net)\n",
    "    net2 = Conv2D(64, kernel_size=3, padding='same', activation='relu')(net1)\n",
    "    net3 = Conv2D(64, kernel_size=1, padding='same', activation='relu')(net2)\n",
    "    \n",
    "    net = Add()([net, net3])\n",
    "    \n",
    "    net = MaxPool2D()(net)\n",
    "    \n",
    "    net = Flatten()(net)\n",
    "    net = Dense(10, activation=\"softmax\")(net)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=net, name='resnet')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_resnet((32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f81bc2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fcf5acf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 26s 16ms/step - loss: 2.3620 - accuracy: 0.1005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x171bb5c70>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow((train_x, train_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00974812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5a26d0e877c4652cf53eb6b13536f4959f02e722fb5eef7979a29d14fb02c8a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('TF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
