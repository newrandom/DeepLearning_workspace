{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ae048a",
   "metadata": {
    "colab_type": "text",
    "id": "7ev9xtnDU0G2",
    "school_cell_uuid": "0be508e1695e4b329b723279d00061ed"
   },
   "source": [
    "# 자동 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6119171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a8e34f",
   "metadata": {
    "colab_type": "text",
    "id": "Mx2ij_jgU0G3",
    "school_cell_uuid": "49fe360451c843d1b115b31818e1165b"
   },
   "source": [
    "`autograd`는 PyTorch에서 핵심적인 기능을 담당하는 하부 패키지이다. \n",
    "\n",
    "autograd는 텐서의 연산에 대해 자동으로 미분값을 구해주는 기능을 한다.\n",
    "\n",
    "- 텐서 자료를 생성할 때, `requires_grad`인수를 `True`로 설정하거나 \n",
    "- `.requires_grad_(True)`를 실행하면\n",
    "\n",
    "그 텐서에 행해지는 모든 연산에 대한 미분값을 계산한다. \n",
    "\n",
    "계산을 멈추고 싶으면 `.detach()`함수나 with을 이용해 `torch.no_grad()`를  이용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e3bf112",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8012fc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8200, 0.6864],\n",
       "        [0.6492, 0.6429]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "748d624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2b78663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6995, 0.6948],\n",
       "        [0.6637, 0.7060]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e255358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미분값을 트래킹 하겠다고 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2427c1",
   "metadata": {
    "colab_type": "text",
    "id": "pe3UmFHEU0G6",
    "school_cell_uuid": "bbe2ffda94494f22aff74255a81349f0"
   },
   "source": [
    "다음으로 이 x에 연산을 수행한다. 다음 코드의 y는 연산의 결과이므로 미분 함수를 가진다. `grad_fn`속성을 출력해 미분 함수를 확인 할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abb61001",
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = torch.sum(x * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "952dc0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.2922, grad_fn=<SumBackward0>) <SumBackward0 object at 0x117e15a90>\n"
     ]
    }
   ],
   "source": [
    "print(y, y.grad_fn)\n",
    "            # 속성값이 있는지가 중요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e2983f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tape.gradient(y, x)\n",
    "y.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd101ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3931e24",
   "metadata": {
    "colab_type": "text",
    "id": "tHMz6Oz0U0G9",
    "school_cell_uuid": "85d36e8f00a4460abff07fb15125a86e"
   },
   "source": [
    "`y.backward()` 함수를 실행하면 x의 미분값이 자동으로 갱신된다. x의 `grad`속성을 확인하면 미분값이 들어 있는 것을 확인 할 수 있다. y를 구하기 위한 x의 연산을 수식으로 쓰면 다음과 같다. \n",
    "\n",
    "$$\n",
    "y = \\displaystyle\\sum_{i=1}^4 3 \\times x_i\n",
    "$$\n",
    "\n",
    "이를 $x_i$에 대해 미분 하면 미분 함수는 다음과 같다. \n",
    "\n",
    "$$\n",
    "\\dfrac{\\partial y}{\\partial x_i} = 3\n",
    "$$\n",
    "\n",
    "실제 미분값과 같은지 확인해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9e95ad",
   "metadata": {
    "colab_type": "text",
    "id": "J_jJvUmpU0HH",
    "school_cell_uuid": "912bc4592afa4dc3a7ae47a96278601a"
   },
   "source": [
    "`backward()`함수는 자동으로 미분값을 계산해 `requires_grad`인수가 True로 설정된 변수의 `grad`속성의 값을 갱신한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5450e53b",
   "metadata": {},
   "source": [
    "`retain_graph` 미분을 연산하기 위해서 사용했던 임시 그래프를 유지 할 것인가를 설정하는 것이다. \n",
    "기본값은 False로 설정되어 있지만 동일한 연산에 대해 여러번 미분을 계산하기 위해서는 True로 설정되어 있어야한다.(`tf.GradientTape`에서 `persistent`와 같음)\n",
    "\n",
    "`torch.autograd.grad()`함수를 사용해 `tf.GradientTape`처럼 사용할 수도 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1909e0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 3.],\n",
       "         [3., 3.]]),)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(y, x)       # 미분 값이 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26131202",
   "metadata": {
    "colab_type": "text",
    "id": "5aFWG_EnU0HK",
    "school_cell_uuid": "a075cd7db9344c589ce6018801d4b519"
   },
   "source": [
    "상황에 따라 특정 연산에는 미분값을 계산하고 싶지 않은 경우에는 \n",
    "\n",
    " - `.detach()`함수\n",
    " - `with torch.no_grad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c947de43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6681, 0.6670],\n",
       "        [0.6601, 0.6695]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.grad)\n",
    "x_d = x.detach()    # 미분값을 트래킹 하지 않는 것. // 학습할 때, 로그를 남길때 많이 쓴다.\n",
    "torch.sigmoid(x_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e77d082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08950931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x_d.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "765629bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# torch.no_grad()\n",
    "print(x.grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_d2 = torch.sigmoid(x)\n",
    "    print(x_d2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d31c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5a26d0e877c4652cf53eb6b13536f4959f02e722fb5eef7979a29d14fb02c8a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('TF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
