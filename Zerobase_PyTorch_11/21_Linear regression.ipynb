{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17cc69a",
   "metadata": {},
   "source": [
    "## PyTorch 선형 회귀 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12ca505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f4de938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11e989270>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac1af429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/newrandom/miniforge3/envs/TF/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "501  0.06263  0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527  0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076  0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959  0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741  0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  const  \n",
       "501     21.0  391.99   9.67    1.0  \n",
       "502     21.0  396.90   9.08    1.0  \n",
       "503     21.0  396.90   5.64    1.0  \n",
       "504     21.0  393.45   6.48    1.0  \n",
       "505     21.0  396.90   7.88    1.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['const'] = np.ones(df.shape[0])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a9fdc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b95fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch 연산 운용\n",
    "x = torch.tensor(df.values)\n",
    "y = torch.tensor(boston.target).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ab150dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([506, 14]), torch.Size([506, 1]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee9d9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "XT = torch.transpose(x, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60565175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 506])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2fba48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.mm(torch.mm(torch.linalg.inv(torch.mm(XT, x)), XT),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14b62e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.matmul(x, w)\n",
    "                # 예측치가 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75e433ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18.4061], dtype=torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf7ccd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.target[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e829253c",
   "metadata": {},
   "source": [
    "#### Gradient descent 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "891fa819",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.rand((14, 1), dtype = torch.float64, requires_grad =True) \n",
    "b = torch.rand((1,1), dtype = torch.float64, requires_grad =True)     # bias 는 1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "008fa32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.mm(w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c09dce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean((z-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c2cacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d54d926e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.6543e+03],\n",
       "         [1.1592e+04],\n",
       "         [1.2824e+04],\n",
       "         [7.4684e+01],\n",
       "         [6.1311e+02],\n",
       "         [6.7807e+03],\n",
       "         [7.6970e+04],\n",
       "         [3.9565e+03],\n",
       "         [1.1487e+04],\n",
       "         [4.6771e+05],\n",
       "         [2.0181e+04],\n",
       "         [3.9043e+05],\n",
       "         [1.4341e+04],\n",
       "         [1.0850e+03]], dtype=torch.float64),\n",
       " tensor([[1084.9567]], dtype=torch.float64))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24937ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(303557.1678, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db0aa84",
   "metadata": {},
   "source": [
    ">`with torch.no_grad()` / `.detach()` 를 써서 print 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f60d583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303557.16782532405\n",
      "303557.16782532405\n"
     ]
    }
   ],
   "source": [
    "print(loss.detach().numpy())\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ac0e050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303557.16782532405"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()\n",
    "        # 아주 간편하게 뽑을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dad7691f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9625],\n",
       "        [0.8798],\n",
       "        [0.6916],\n",
       "        [0.0976],\n",
       "        [0.5441],\n",
       "        [0.6069],\n",
       "        [0.7656],\n",
       "        [0.2674],\n",
       "        [0.7172],\n",
       "        [0.4656],\n",
       "        [0.7843],\n",
       "        [0.7482],\n",
       "        [0.5919],\n",
       "        [0.0070]], dtype=torch.float64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df6bf3",
   "metadata": {},
   "source": [
    "#### assign 대신에 data에 접근해서 값을 수정 \n",
    "\n",
    "tensor.data = 다른데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c0a16c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f276e5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - loss : 303557.16782532405\n",
      "1 - loss : 119223.98659357797\n",
      "2 - loss : 79124.14612788572\n",
      "3 - loss : 52663.83577694337\n",
      "4 - loss : 35201.07677258205\n",
      "5 - loss : 23673.78108793309\n",
      "6 - loss : 16062.0358640329\n",
      "7 - loss : 11033.399307362255\n",
      "8 - loss : 7708.920110912625\n",
      "9 - loss : 5508.792152027679\n",
      "10 - loss : 4050.540603569035\n",
      "11 - loss : 3081.8603939022373\n",
      "12 - loss : 2436.3130901562427\n",
      "13 - loss : 2004.1023413418766\n",
      "14 - loss : 1712.795894144592\n",
      "15 - loss : 1514.6088658572073\n",
      "16 - loss : 1378.0151509354187\n",
      "17 - loss : 1282.2138811644047\n",
      "18 - loss : 1213.4792221507973\n",
      "19 - loss : 1162.7525127944639\n",
      "20 - loss : 1124.0539164537608\n",
      "21 - loss : 1093.4346631281346\n",
      "22 - loss : 1068.285892621278\n",
      "23 - loss : 1046.8827296477364\n",
      "24 - loss : 1028.0835297906765\n",
      "25 - loss : 1011.1314840058294\n",
      "26 - loss : 995.5237440302701\n",
      "27 - loss : 980.925088042254\n",
      "28 - loss : 967.11096738067\n",
      "29 - loss : 953.929934560666\n",
      "30 - loss : 941.2788562389089\n",
      "31 - loss : 929.0865598461073\n",
      "32 - loss : 917.3030435611212\n",
      "33 - loss : 905.8923562141969\n",
      "34 - loss : 894.8278981277612\n",
      "35 - loss : 884.0893189955069\n",
      "36 - loss : 873.6604693127304\n",
      "37 - loss : 863.5280468448684\n",
      "38 - loss : 853.6807016393062\n",
      "39 - loss : 844.1084435748686\n",
      "40 - loss : 834.8022495382296\n",
      "41 - loss : 825.7538023405336\n",
      "42 - loss : 816.9553165911799\n",
      "43 - loss : 808.3994219861121\n",
      "44 - loss : 800.0790845212921\n",
      "45 - loss : 791.9875527737989\n",
      "46 - loss : 784.1183207676455\n",
      "47 - loss : 776.4651018272015\n",
      "48 - loss : 769.0218097247588\n",
      "49 - loss : 761.7825446845552\n",
      "50 - loss : 754.7415826339826\n",
      "51 - loss : 747.8933666392\n",
      "52 - loss : 741.2324998229121\n",
      "53 - loss : 734.7537392999128\n",
      "54 - loss : 728.4519908229494\n",
      "55 - loss : 722.3223039349974\n",
      "56 - loss : 716.3598674923909\n",
      "57 - loss : 710.560005468349\n",
      "58 - loss : 704.918172976238\n",
      "59 - loss : 699.4299524715718\n",
      "60 - loss : 694.0910501047684\n",
      "61 - loss : 688.8972922052861\n",
      "62 - loss : 683.84462188346\n",
      "63 - loss : 678.9290957401462\n",
      "64 - loss : 674.146880676817\n",
      "65 - loss : 669.4942508004159\n",
      "66 - loss : 664.9675844184356\n",
      "67 - loss : 660.563361120443\n",
      "68 - loss : 656.2781589428142\n",
      "69 - loss : 652.1086516138034\n",
      "70 - loss : 648.0516058763437\n",
      "71 - loss : 644.1038788861728\n",
      "72 - loss : 640.2624156830134\n",
      "73 - loss : 636.5242467326702\n",
      "74 - loss : 632.8864855379877\n",
      "75 - loss : 629.3463263167004\n",
      "76 - loss : 625.9010417442764\n",
      "77 - loss : 622.5479807599135\n",
      "78 - loss : 619.2845664339143\n",
      "79 - loss : 616.1082938947106\n",
      "80 - loss : 613.0167283138679\n",
      "81 - loss : 610.0075029474402\n",
      "82 - loss : 607.0783172321013\n",
      "83 - loss : 604.2269349345177\n",
      "84 - loss : 601.4511823524717\n",
      "85 - loss : 598.7489465662891\n",
      "86 - loss : 596.1181737391629\n",
      "87 - loss : 593.5568674650076\n",
      "88 - loss : 591.0630871625108\n",
      "89 - loss : 588.6349465140937\n",
      "90 - loss : 586.2706119485248\n",
      "91 - loss : 583.9683011659615\n",
      "92 - loss : 581.7262817042392\n",
      "93 - loss : 579.542869545251\n",
      "94 - loss : 577.4164277602965\n",
      "95 - loss : 575.3453651933115\n",
      "96 - loss : 573.3281351809192\n",
      "97 - loss : 571.3632343082734\n",
      "98 - loss : 569.4492011996899\n",
      "99 - loss : 567.5846153430995\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    z = x.matmul(w) + b\n",
    "    loss = torch.mean((y-z)**2)\n",
    "\n",
    "    loss.backward()\n",
    "            # backward를 하면 이전의 값이 축적이 되서 업데이트가 제대로 이뤄지지 않는다.\n",
    "\n",
    "    w.data = w.data - w.grad * lr\n",
    "    b.data = b.data - b.grad * lr\n",
    "    \n",
    "    print('{} - loss : {}'.format(epoch, loss.item()))\n",
    "\n",
    "    w.grad.zero_()  # w 안의 grad가 0으로 초기화 된다.\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "070a8d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - loss : 565.7680959473693\n",
      "1 - loss : 563.9983008315796\n",
      "2 - loss : 562.273925345359\n",
      "3 - loss : 560.5937013194101\n",
      "4 - loss : 558.9563960453837\n",
      "5 - loss : 557.3608112842763\n",
      "6 - loss : 555.8057823025583\n",
      "7 - loss : 554.290176935254\n",
      "8 - loss : 552.8128946752206\n",
      "9 - loss : 551.3728657878955\n",
      "10 - loss : 549.9690504507961\n",
      "11 - loss : 548.6004379170832\n",
      "12 - loss : 547.2660457025132\n",
      "13 - loss : 545.9649187951268\n",
      "14 - loss : 544.6961288870359\n",
      "15 - loss : 543.4587736276931\n",
      "16 - loss : 542.2519758980418\n",
      "17 - loss : 541.074883104964\n",
      "18 - loss : 539.9266664954566\n",
      "19 - loss : 538.8065204899867\n",
      "20 - loss : 537.7136620344868\n",
      "21 - loss : 536.647329970473\n",
      "22 - loss : 535.6067844227732\n",
      "23 - loss : 534.5913062043795\n",
      "24 - loss : 533.6001962379406\n",
      "25 - loss : 532.6327749934331\n",
      "26 - loss : 531.6883819415555\n",
      "27 - loss : 530.766375022408\n",
      "28 - loss : 529.8661301290299\n",
      "29 - loss : 528.9870406053783\n",
      "30 - loss : 528.1285167583453\n",
      "31 - loss : 527.2899853834208\n",
      "32 - loss : 526.4708893036188\n",
      "33 - loss : 525.6706869212982\n",
      "34 - loss : 524.8888517825136\n",
      "35 - loss : 524.1248721535517\n",
      "36 - loss : 523.3782506093053\n",
      "37 - loss : 522.6485036331605\n",
      "38 - loss : 521.9351612280715\n",
      "39 - loss : 521.2377665385106\n",
      "40 - loss : 520.5558754829902\n",
      "41 - loss : 519.8890563968603\n",
      "42 - loss : 519.236889685094\n",
      "43 - loss : 518.5989674847845\n",
      "44 - loss : 517.974893337077\n",
      "45 - loss : 517.3642818682754\n",
      "46 - loss : 516.7667584798678\n",
      "47 - loss : 516.1819590472174\n",
      "48 - loss : 515.6095296266801\n",
      "49 - loss : 515.049126170913\n",
      "50 - loss : 514.5004142521419\n",
      "51 - loss : 513.9630687931688\n",
      "52 - loss : 513.4367738059002\n",
      "53 - loss : 512.9212221371877\n",
      "54 - loss : 512.4161152217744\n",
      "55 - loss : 511.92116284215234\n",
      "56 - loss : 511.4360828951319\n",
      "57 - loss : 510.9606011649412\n",
      "58 - loss : 510.4944511026691\n",
      "59 - loss : 510.03737361187524\n",
      "60 - loss : 509.58911684019745\n",
      "61 - loss : 509.14943597678337\n",
      "62 - loss : 508.7180930553886\n",
      "63 - loss : 508.2948567629804\n",
      "64 - loss : 507.8795022536931\n",
      "65 - loss : 507.4718109679864\n",
      "66 - loss : 507.0715704568601\n",
      "67 - loss : 506.6785742109846\n",
      "68 - loss : 506.2926214946099\n",
      "69 - loss : 505.9135171841174\n",
      "70 - loss : 505.54107161108914\n",
      "71 - loss : 505.1751004097622\n",
      "72 - loss : 504.81542436875105\n",
      "73 - loss : 504.46186928691515\n",
      "74 - loss : 504.11426583325743\n",
      "75 - loss : 503.77244941073974\n",
      "76 - loss : 503.4362600239076\n",
      "77 - loss : 503.1055421502156\n",
      "78 - loss : 502.7801446149508\n",
      "79 - loss : 502.45992046965523\n",
      "80 - loss : 502.1447268739463\n",
      "81 - loss : 501.8344249806428\n",
      "82 - loss : 501.5288798241027\n",
      "83 - loss : 501.2279602116842\n",
      "84 - loss : 500.93153861824084\n",
      "85 - loss : 500.6394910835671\n",
      "86 - loss : 500.35169711271345\n",
      "87 - loss : 500.0680395790853\n",
      "88 - loss : 499.78840463025523\n",
      "89 - loss : 499.51268159640733\n",
      "90 - loss : 499.24076290134184\n",
      "91 - loss : 498.9725439759678\n",
      "92 - loss : 498.70792317421694\n",
      "93 - loss : 498.44680169130595\n",
      "94 - loss : 498.1890834842862\n",
      "95 - loss : 497.93467519481544\n",
      "96 - loss : 497.683486074087\n",
      "97 - loss : 497.43542790986135\n",
      "98 - loss : 497.19041495553455\n",
      "99 - loss : 496.9483638611934\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    z = x.matmul(w) + b\n",
    "    loss = torch.mean((y-z)**2)\n",
    "\n",
    "    grads = torch.autograd.grad(loss, [w,b])\n",
    "\n",
    "    w.data = w.data - grads[0] * lr\n",
    "    b.data = b.data - grads[1] * lr\n",
    "    \n",
    "    print('{} - loss : {}'.format(epoch, loss.item()))\n",
    "\n",
    "    w.grad.zero_()  # w 안의 grad가 0으로 초기화 된다.\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e14c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fbba60f",
   "metadata": {},
   "source": [
    "#### optimizer 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "419e4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD([w, b], lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b01bf1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - loss : 496.7091936065956\n",
      "1 - loss : 496.472825436027\n",
      "2 - loss : 496.23918279497764\n",
      "3 - loss : 496.00819126859074\n",
      "4 - loss : 495.7797785218309\n",
      "5 - loss : 495.55387424132726\n",
      "6 - loss : 495.33041007884174\n",
      "7 - loss : 495.10931959631796\n",
      "8 - loss : 494.8905382124682\n",
      "9 - loss : 494.6740031508518\n",
      "10 - loss : 494.45965338940766\n",
      "11 - loss : 494.24742961139583\n",
      "12 - loss : 494.03727415771306\n",
      "13 - loss : 493.82913098054036\n",
      "14 - loss : 493.6229455982865\n",
      "15 - loss : 493.41866505179297\n",
      "16 - loss : 493.216237861762\n",
      "17 - loss : 493.01561398737596\n",
      "18 - loss : 492.81674478607323\n",
      "19 - loss : 492.61958297445\n",
      "20 - loss : 492.42408259025336\n",
      "21 - loss : 492.2301989554401\n",
      "22 - loss : 492.03788864026535\n",
      "23 - loss : 491.84710942837734\n",
      "24 - loss : 491.6578202828886\n",
      "25 - loss : 491.4699813133939\n",
      "26 - loss : 491.2835537439126\n",
      "27 - loss : 491.0984998817258\n",
      "28 - loss : 490.9147830870862\n",
      "29 - loss : 490.7323677437743\n",
      "30 - loss : 490.5512192304778\n",
      "31 - loss : 490.3713038929714\n",
      "32 - loss : 490.1925890170752\n",
      "33 - loss : 490.0150428023686\n",
      "34 - loss : 489.8386343366392\n",
      "35 - loss : 489.6633335710465\n",
      "36 - loss : 489.48911129597985\n",
      "37 - loss : 489.3159391175924\n",
      "38 - loss : 489.14378943498934\n",
      "39 - loss : 488.9726354180557\n",
      "40 - loss : 488.80245098590416\n",
      "41 - loss : 488.63321078592395\n",
      "42 - loss : 488.4648901734173\n",
      "43 - loss : 488.2974651918047\n",
      "44 - loss : 488.13091255338304\n",
      "45 - loss : 487.96520962062357\n",
      "46 - loss : 487.8003343879901\n",
      "47 - loss : 487.6362654642688\n",
      "48 - loss : 487.4729820553895\n",
      "49 - loss : 487.31046394772864\n",
      "50 - loss : 487.14869149187854\n",
      "51 - loss : 486.9876455868721\n",
      "52 - loss : 486.8273076648458\n",
      "53 - loss : 486.66765967613395\n",
      "54 - loss : 486.5086840747788\n",
      "55 - loss : 486.3503638044464\n",
      "56 - loss : 486.19268228473504\n",
      "57 - loss : 486.03562339786794\n",
      "58 - loss : 485.87917147575774\n",
      "59 - loss : 485.72331128743207\n",
      "60 - loss : 485.568028026811\n",
      "61 - loss : 485.4133073008267\n",
      "62 - loss : 485.25913511787536\n",
      "63 - loss : 485.10549787659085\n",
      "64 - loss : 484.95238235493406\n",
      "65 - loss : 484.79977569958606\n",
      "66 - loss : 484.64766541563756\n",
      "67 - loss : 484.49603935656876\n",
      "68 - loss : 484.34488571450646\n",
      "69 - loss : 484.19419301075646\n",
      "70 - loss : 484.04395008659884\n",
      "71 - loss : 483.89414609434056\n",
      "72 - loss : 483.7447704886202\n",
      "73 - loss : 483.59581301795316\n",
      "74 - loss : 483.447263716516\n",
      "75 - loss : 483.29911289615785\n",
      "76 - loss : 483.15135113863766\n",
      "77 - loss : 483.00396928807606\n",
      "78 - loss : 482.8569584436212\n",
      "79 - loss : 482.71030995231695\n",
      "80 - loss : 482.56401540217183\n",
      "81 - loss : 482.4180666154221\n",
      "82 - loss : 482.27245564198194\n",
      "83 - loss : 482.1271747530787\n",
      "84 - loss : 481.9822164350633\n",
      "85 - loss : 481.8375733833974\n",
      "86 - loss : 481.693238496805\n",
      "87 - loss : 481.5492048715904\n",
      "88 - loss : 481.4054657961131\n",
      "89 - loss : 481.262014745419\n",
      "90 - loss : 481.11884537602\n",
      "91 - loss : 480.97595152082044\n",
      "92 - loss : 480.8333271841855\n",
      "93 - loss : 480.69096653714774\n",
      "94 - loss : 480.5488639127461\n",
      "95 - loss : 480.4070138014978\n",
      "96 - loss : 480.2654108469938\n",
      "97 - loss : 480.1240498416212\n",
      "98 - loss : 479.98292572240115\n",
      "99 - loss : 479.84203356694616\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    z = x.matmul(w) + b\n",
    "    loss = torch.mean((z - y )**2)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    opt.step()\n",
    "    print('{} - loss : {}'.format(epoch, loss.item()))\n",
    "    opt.zero_grad()     # gradient 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00076369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c9497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6297ccac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5a26d0e877c4652cf53eb6b13536f4959f02e722fb5eef7979a29d14fb02c8a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('TF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
